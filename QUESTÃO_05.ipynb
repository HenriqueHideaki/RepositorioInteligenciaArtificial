{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKcw/t5WBE7ZF7AP7i+mXp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenriqueHideaki/RepositorioInteligenciaArtificial/blob/main/QUEST%C3%83O_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5-) Apresente um estudo sobre as seguintes medidas de desempenho de classificadores de padrões: Acurácia, Precisão e F-Score"
      ],
      "metadata": {
        "id": "gQffpx2qsKyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Acurácia"
      ],
      "metadata": {
        "id": "rI2469rbDzOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A acurácia representa basicamente a fração de previsões corretas feitas em um determinado conjunto de teste, ou seja, o número de acertos positivos dividido pelo número total de exemplos, o ideal é que ela seja usada em dados com a mesma proporção de exemplos para cada classe, suponha um dataset com 0% dos exemplos pertençam a uma classe, só de classificar todos os exemplos naquela classe como positivos já se atinge uma precisão de 80%, mesmo que todos os exemplos da outra classe estejam classificados incorretamente."
      ],
      "metadata": {
        "id": "KhyECY6GCu2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pode ser utilizado em python usando o metodo accuracy_score da biblioteca sklearn"
      ],
      "metadata": {
        "id": "68mdevjIEYOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "9sqt8HZpELpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Precisão\n"
      ],
      "metadata": {
        "id": "KHpqyw63ESvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Já a precisão define, entre os exemplos classificados como positivos(pelo modelo), quanto eram realmente verdadeiros, ou seja, a fração entre as previsões positivas corretas pelas previsões corretas, ela é utilizada onde os falsos positivos são considerados mais prejudiciais que os falsos positivos  "
      ],
      "metadata": {
        "id": "0E_XvoWMEoGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Uso em python"
      ],
      "metadata": {
        "id": "6mbacYECFQpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "DKv3iLi_B_cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#F-Score"
      ],
      "metadata": {
        "id": "7eqAnmmdFUUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Para entender a métrica F-Score, antes precisamos entender a metrica Recall ou recuperação, essa métrica representa a fração entre as previsões positivas corretas e os exemplos positivos,\n",
        "##Recall"
      ],
      "metadata": {
        "id": "6zN2SoIUGxWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "zf8I6inAFW3i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A metrica recall combina a precisão de um classificador em um única métrica, tomando sua média harmonica, é utilizada para comparar o desempenho de dois classificadores.\n",
        "##F1 = 2 * (precision * recall) / (precision + recall)"
      ],
      "metadata": {
        "id": "oxLCH3YtG54Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "sklearn.metrics.f1_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "Yh6Rk_IoGvvo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}